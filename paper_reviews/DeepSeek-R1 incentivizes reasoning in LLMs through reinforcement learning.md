## paper 
DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning

## Summary 
- Reasoning abilities of LLMs can be incentivized through pure reinforcement learning (RL) obviating the need for human-labelled reasoning trajectories.
  
- The self-evolution of DeepSeek-R1-Zero underscores the power and beauty of RL: rather tha explicitly teaching the model how to solve a problem, it simply provide it with the right incentives and it automously develops advanced problem-solving strategy. This serves as a reminder of the potential of RL to unlock higher levels of capability in LLMs, paving the way for more autonomous and adaptive models in the future.

- developing reasoning abiities through self-evolution in RL framework, with minimal reliance on human labelling efforts, specifically, it build on DeepSeek-V3 Base and use Group Relative Policy Optimization (GRPO) as our RL framework. 


## Terminology to learn 

- SFT (Supervised Fine Tuning)
  
- Test-time scaling

- Test-time computation scaling approach

- How to measure LLM model's inherent safety level 
